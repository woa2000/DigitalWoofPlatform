# ğŸ“‹ Resumo PrÃ©-ExecuÃ§Ã£o: Anamnese Digital

## ğŸ†” IdentificaÃ§Ã£o do Plano

- **TÃ­tulo:** Anamnese Digital - Execution Plan
- **VersÃ£o:** 1.0
- **Status:** ğŸ“… Pronto para execuÃ§Ã£o por agente
- **Agente ResponsÃ¡vel:** Backend_Developer
- **Data de GeraÃ§Ã£o:** 2025-09-05
- **Modo de ExecuÃ§Ã£o:** dry-run

## ğŸ¯ Escopo (8-12 bullets)

â€¢ **RF-1.1:** Sistema de validaÃ§Ã£o automÃ¡tica para 1 site obrigatÃ³rio + atÃ© 10 URLs de redes sociais
â€¢ **RF-1.2:** Pipeline de anÃ¡lise mock que processa URLs e retorna diagnÃ³stico estruturado em â‰¤ 2 min  
â€¢ **RF-1.3:** PersistÃªncia no Supabase com deduplicaÃ§Ã£o automÃ¡tica por URL normalizada
â€¢ **RF-1.4:** Interface de resultados estruturados em 8 seÃ§Ãµes (Identidade, Personas, UX, Ecosystem, etc.)
â€¢ **RF-1.5:** CRUD completo com histÃ³rico, reprocessamento e exclusÃ£o de anÃ¡lises
â€¢ **Performance:** API latency p95 â‰¤ 300ms, processamento â‰¤ 2min, success rate > 95%
â€¢ **DeduplicaÃ§Ã£o:** 100% efetiva para URLs normalizadas idÃªnticas usando hash determinÃ­stico
â€¢ **Stack:** Node.js + Express + TypeScript + Supabase + Drizzle ORM + Zod validation
â€¢ **SeguranÃ§a:** JWT auth, RLS policies, input sanitization, rate limiting configurÃ¡vel
â€¢ **Observabilidade:** Logs JSON estruturados, mÃ©tricas de performance, alertas automÃ¡ticos
â€¢ **Compliance:** LGPD, apenas dados pÃºblicos, PII masking, respeito ao robots.txt
â€¢ **Escalabilidade:** Preparado para transiÃ§Ã£o de mock para IA real (OpenAI integration)

## âœ… CritÃ©rios de AceitaÃ§Ã£o

1. Database schema implementado com migrations executadas sem erro
2. Sistema de validaÃ§Ã£o de URLs rejeita formatos invÃ¡lidos com mensagens claras  
3. NormalizaÃ§Ã£o de URLs remove www, trailing slash, converte para lowercase
4. Mock analysis engine retorna 8 seÃ§Ãµes estruturadas em formato JSON vÃ¡lido
5. DeduplicaÃ§Ã£o impede criaÃ§Ã£o de anÃ¡lises para URLs jÃ¡ processadas
6. API REST endpoints funcionais: POST /api/anamnesis, GET /api/anamnesis/:id, GET /api/anamnesis
7. Error handling robusto com status tracking (queued â†’ running â†’ done/error)
8. Unit tests com cobertura conforme definido em docs/TODO.md
9. Integration tests validando fluxo completo API â†’ Database
10. Logging estruturado com campos obrigatÃ³rios (contextId, userId, timestamp)
11. Performance targets atingidos: p95 â‰¤ 300ms API, â‰¤ 2min processamento
12. Security scan sem vulnerabilidades crÃ­ticas (OWASP ZAP)

## ğŸ”Œ Interfaces & Dados

### API Endpoints
- **POST /api/anamnesis** - Cria nova anÃ¡lise com validaÃ§Ã£o Zod
- **GET /api/anamnesis/:id** - Retorna anÃ¡lise com findings estruturados  
- **GET /api/anamnesis** - Lista anÃ¡lises do usuÃ¡rio com paginaÃ§Ã£o
- **DELETE /api/anamnesis/:id** - Remove anÃ¡lise (soft delete)

### Database Schema
```sql
-- Tabelas principais: anamnesis_analysis, anamnesis_source, anamnesis_finding
-- Indexes: normalized_url, user_id, status para performance
-- Constraints: hash unique, RLS policies por accountId
```

### Response Format
```json
{
  "success": true,
  "data": {
    "id": "uuid",
    "status": "done|running|queued|error", 
    "findings": { /* 8 seÃ§Ãµes estruturadas */ }
  }
}
```

## ğŸ› ï¸ Stack & PadrÃµes

- **Runtime:** Node.js + TypeScript (strict mode)
- **Framework:** Express.js com middleware stack
- **Database:** Supabase PostgreSQL + Drizzle ORM
- **Validation:** Zod schemas para todos inputs/outputs
- **Auth:** Supabase Auth + JWT + RBAC
- **Error Handling:** Structured errors com error codes
- **Logging:** JSON format (Winston/Pino) com correlation IDs
- **Testing:** Jest para unit/integration tests
- **Security:** OWASP ASVS controls, input sanitization
- **Performance:** Connection pooling, query optimization, indexing

## ğŸ“Š MÃ©tricas & SLOs

- **API Latency:** p95 â‰¤ 300ms para endpoints CRUD
- **Processing Time:** p95 â‰¤ 2min para anÃ¡lise mock completa  
- **Success Rate:** > 95% para URLs vÃ¡lidas
- **Error Rate:** < 5% de falhas irrecuperÃ¡veis
- **Availability:** 99.5% SLO target
- **Deduplication:** 100% effectiveness para URLs normalizadas
- **Test Coverage:** Conforme definido em docs/TODO.md
- **Security:** 0 vulnerabilidades crÃ­ticas no scan

## âš ï¸ Riscos & MitigaÃ§Ãµes

1. **Mock Realismo** - Mock pode nÃ£o refletir complexidade real da IA
   - *MitigaÃ§Ã£o:* Output estruturado compatÃ­vel com futura integraÃ§Ã£o OpenAI
   
2. **Performance Database** - Queries lentas com volume de anÃ¡lises
   - *MitigaÃ§Ã£o:* Indexing otimizado, connection pooling, query optimization
   
3. **URL Edge Cases** - Sites com estruturas de URL complexas  
   - *MitigaÃ§Ã£o:* Test cases extensivos, fallback normalization
   
4. **Rate Limiting Abuse** - Potencial abuse de endpoints de anÃ¡lise
   - *MitigaÃ§Ã£o:* Rate limiting configurÃ¡vel, monitoring proativo
   
5. **Data Privacy** - Coleta inadvertida de PII de sites analisados
   - *MitigaÃ§Ã£o:* PII masking automÃ¡tico, apenas dados pÃºblicos

## ğŸ”— DependÃªncias

### TÃ©cnicas
- Supabase instance configurada e acessÃ­vel
- Database permissions para migrations
- Environment variables definidas (.env)
- Node.js + npm dependencies instaladas

### Entre Planos  
- **Nenhuma** - Esta Ã© a feature inicial do sistema
- **Consume:** Brand_Voice_JSON_Plan.md consumirÃ¡ dados desta anÃ¡lise
- **Afeta:** Onboarding_Marca_Plan.md pode usar insights para pre-fill

### Ordem Sugerida
1. Database schema & migrations
2. URL validation & normalization  
3. Mock analysis engine
4. CRUD operations
5. REST API endpoints
6. Testing & quality assurance

## ğŸš« Gaps/Bloqueios

### [âš ï¸ DOCUMENTAÃ‡ÃƒO PENDENTE]
1. **APM Tool** - Ferramenta de observabilidade nÃ£o definida
   - *Owner:* DevOps_Specialist
   - *Next Step:* Definir entre DataDog, New Relic, ou alternativa open-source

2. **Test Coverage Target** - Percentual mÃ­nimo nÃ£o especificado
   - *Owner:* QA_Engineer  
   - *Next Step:* Consultar docs/TODO.md e definir target

3. **Rollback Strategy** - Processo especÃ­fico para rollback de migrations
   - *Owner:* Database_Admin
   - *Next Step:* Documentar procedimento de rollback seguro

### [âš ï¸ PERGUNTAS ABERTAS]
1. **AI Integration Timeline** - Quando substituir mock por OpenAI real?
   - *Owner:* Tech_Lead
   - *Next Step:* Roadmap definition meeting

## ğŸ“‹ Plano de ExecuÃ§Ã£o

1. **Foundation** (Database_Admin): Schema design â†’ migrations â†’ validation
2. **Core Logic** (Backend_Developer): URL validation â†’ normalization â†’ deduplication  
3. **Mock Engine** (Backend_Developer): Analysis engine â†’ structured output â†’ timing
4. **Service Layer** (Backend_Developer): CRUD operations â†’ error handling â†’ status tracking
5. **API Layer** (Backend_Developer): REST endpoints â†’ middleware â†’ authentication
6. **Quality** (QA_Engineer): Unit tests â†’ integration tests â†’ contract validation
7. **Observability** (Backend_Developer): Structured logging â†’ metrics collection
8. **Monitoring** (DevOps_Specialist): Performance monitoring â†’ alerting setup
9. **Integration** (QA_Engineer): End-to-end validation â†’ performance testing
10. **Documentation** (Backend_Developer): API docs â†’ runbooks â†’ deployment guide

---
*Tempo estimado total: 8-10 dias de desenvolvimento*  
*PrÃ³ximo passo: Revisar gaps e executar em modo `execute` quando desbloqueados*